{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chief-journalist",
   "metadata": {
    "id": "chief-journalist"
   },
   "source": [
    "# Advanced Certification Program in Computational Data Science\n",
    "## A program by IISc and TalentSprint\n",
    "### Mini-Project: Linear Regression with Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-shaft",
   "metadata": {
    "id": "arabic-shaft"
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-thread",
   "metadata": {
    "id": "prospective-thread"
   },
   "source": [
    "Predict the bike-sharing counts per hour based on the features including weather, day, time, humidity, wind speed, season e.t.c."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-christmas",
   "metadata": {
    "id": "organic-christmas"
   },
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-begin",
   "metadata": {
    "id": "phantom-begin"
   },
   "source": [
    "At the end of the mini-project, you will be able to :\n",
    "\n",
    "* perform data exploration and visualization\n",
    "* implement linear regression using sklearn and optimization\n",
    "* apply regularization on regression using Lasso, Ridge and Elasticnet techniques\n",
    "* calculate and compare the MSE value of each regression technique\n",
    "* analyze the features that are best contributing to the target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-quilt",
   "metadata": {
    "id": "received-quilt"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-replication",
   "metadata": {
    "id": "sporting-replication"
   },
   "source": [
    "The dataset chosen for this mini-project is [Bike Sharing Dataset](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset).  This dataset contains the hourly and daily count of rental bikes between the years 2011 and 2012 in the capital bike share system with the corresponding weather and seasonal information. This dataset consists of 17389 instances of each 16 features. \n",
    "\n",
    "Bike sharing systems are a new generation of traditional bike rentals where the whole process from membership, rental and return has become automatic. Through these systems, the user can easily rent a bike from a particular position and return to another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousand bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues.\n",
    "\n",
    "Apart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. As opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position are explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that the most important events in the city could be detected via monitoring these data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ISKMyTABbfp",
   "metadata": {
    "id": "5ISKMyTABbfp"
   },
   "source": [
    "<img src=\"https://s26551.pcdn.co/wp-content/uploads/2012/02/resize-va-sq-bikeshare.jpg\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-evening",
   "metadata": {
    "id": "binary-evening"
   },
   "source": [
    "### Data Fields\n",
    "\n",
    "* dteday - hourly date\n",
    "* season - 1 = spring, 2 = summer, 3 = fall, 4 = winter\n",
    "* hr - hour\n",
    "* holiday - whether the day is considered a holiday\n",
    "* workingday - whether the day is neither a weekend nor holiday\n",
    "* weathersit -<br>\n",
    "    1 - Clear, Few clouds, Partly cloudy, Partly cloudy <br>\n",
    "    2 - Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist<br>\n",
    "    3 - Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds<br>\n",
    "    4 - Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog<br>   \n",
    "* temp - temperature in Celsius\n",
    "* atemp - \"feels like\" temperature in Celsius\n",
    "* humidity - relative humidity\n",
    "* windspeed - wind speed\n",
    "* casual - number of non-registered user rentals initiated\n",
    "* registered - number of registered user rentals initiated\n",
    "* cnt - number of total rentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-fields",
   "metadata": {
    "id": "perfect-fields"
   },
   "source": [
    "## Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-gasoline",
   "metadata": {
    "id": "quick-gasoline"
   },
   "source": [
    "**Regularization:** It is a form of regression that shrinks the coefficient estimates towards zero. In other words, this technique discourages learning a more complex or flexible model, to avoid the risk of overfitting. A simple relation for linear regression looks like this.\n",
    "\n",
    "$Y ≈ β_0 + β_1 X_1 + β_2 X_2 + …+ β_p X_p$\n",
    "\n",
    " Here $Y$ represents the learned relation and $β$ represents the coefficient estimates for different variables or predictors(X).\n",
    " \n",
    " If there is noise in the training data, then the estimated coefficients won’t generalize well to the future data. This is where regularization comes in and shrinks or regularizes these learned estimates towards zero.\n",
    " \n",
    "Below are the Regularization techniques:\n",
    " \n",
    " * Ridge Regression\n",
    " * Lasso Regression\n",
    " * Elasticnet Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-battle",
   "metadata": {
    "id": "declared-battle"
   },
   "source": [
    "## Grading = 10 Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-ownership",
   "metadata": {
    "cellView": "form",
    "id": "virtual-ownership"
   },
   "outputs": [],
   "source": [
    "#@title Download the dataset\n",
    "!wget -qq https://cdn.iisc.talentsprint.com/CDS/MiniProjects/Bike_Sharing_Dataset.zip\n",
    "!unzip Bike_Sharing_Dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-survivor",
   "metadata": {
    "id": "cross-survivor"
   },
   "source": [
    "#### Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-essence",
   "metadata": {
    "id": "ethical-essence"
   },
   "outputs": [],
   "source": [
    "# Loading the Required Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-scotland",
   "metadata": {
    "id": "through-scotland"
   },
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-consolidation",
   "metadata": {
    "id": "comic-consolidation"
   },
   "outputs": [],
   "source": [
    "# Read the hour.csv file\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-overall",
   "metadata": {
    "id": "ordered-overall"
   },
   "source": [
    "print the first five rows of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-committee",
   "metadata": {
    "id": "exterior-committee"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67gbVvLIsoS",
   "metadata": {
    "id": "e67gbVvLIsoS"
   },
   "source": [
    "print the datatypes of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-shelter",
   "metadata": {
    "id": "sharp-shelter"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-block",
   "metadata": {
    "id": "opponent-block"
   },
   "source": [
    "### Task flow with respect to feature processing and model training\n",
    "\n",
    "* Explore and analyze the data\n",
    "\n",
    "* Identify continuous features and categorical features\n",
    "\n",
    "* Apply scaling on continuous features and one-hot encoding on categorical features\n",
    "\n",
    "* Separate the features, targets and split the data into train and test\n",
    "\n",
    "* Find the coefficients of the features using normal equation and find the cost (error)\n",
    "\n",
    "* Apply batch gradient descent technique and find the best coefficients\n",
    "\n",
    "* Apply SGD Regressor using sklearn\n",
    "\n",
    "* Apply linear regression using sklearn\n",
    "\n",
    "* Apply Lasso, Ridge, Elasticnet Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-penny",
   "metadata": {
    "id": "magnetic-penny"
   },
   "source": [
    "### EDA &  Visualization ( 2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-techno",
   "metadata": {
    "id": "constitutional-techno"
   },
   "source": [
    "#### Visualize the hour (hr) column with an appropriate plot and find the busy hours of bike sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-comfort",
   "metadata": {
    "id": "uniform-comfort"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-export",
   "metadata": {
    "id": "flexible-export"
   },
   "source": [
    "#### Visualize the distribution of count, casual and registered variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-introduction",
   "metadata": {
    "id": "manufactured-introduction"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE for distribuiton of count variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-involvement",
   "metadata": {
    "id": "powerful-involvement"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE for distribuiton of casual variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-consideration",
   "metadata": {
    "id": "inside-consideration"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE for distribuiton of registered variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-burton",
   "metadata": {
    "id": "twelve-burton"
   },
   "source": [
    "#### Describe the relation of weekday, holiday and working day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-proof",
   "metadata": {
    "id": "afraid-proof"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-allowance",
   "metadata": {
    "id": "thrown-allowance"
   },
   "source": [
    "#### Visualize the month wise count of both casual and registered for the year 2011 and 2012 separately.\n",
    "\n",
    "Hint: Stacked barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-spanking",
   "metadata": {
    "id": "collective-spanking"
   },
   "outputs": [],
   "source": [
    "# stacked bar chart for year 2011\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-court",
   "metadata": {
    "id": "joined-court"
   },
   "outputs": [],
   "source": [
    "# stacked bar chart for year 2012\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-driver",
   "metadata": {
    "id": "fifty-driver"
   },
   "source": [
    "#### Analyze the correlation between features with heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-coalition",
   "metadata": {
    "id": "instant-coalition"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-diary",
   "metadata": {
    "id": "pursuant-diary"
   },
   "source": [
    "#### Visualize the box plot of casual and registered variables to check the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-robert",
   "metadata": {
    "id": "stainless-robert"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-heritage",
   "metadata": {
    "id": "comparative-heritage"
   },
   "source": [
    "### Pre-processing and Data Engineering (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-scotland",
   "metadata": {
    "id": "massive-scotland"
   },
   "source": [
    "#### Drop unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-lawyer",
   "metadata": {
    "id": "appreciated-lawyer"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nASeXE_7JC0L",
   "metadata": {
    "id": "nASeXE_7JC0L"
   },
   "source": [
    "#### Identify categorical and continuous variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-jersey",
   "metadata": {
    "id": "available-jersey"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-concrete",
   "metadata": {
    "id": "corrected-concrete"
   },
   "source": [
    "#### Feature scaling\n",
    "\n",
    "Feature scaling is essential for machine learning algorithms, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance. Apply scaling on the continuous variables on the given data.\n",
    "\n",
    "Hint: `MinMaxScaler` or `StandardScaler`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-leisure",
   "metadata": {
    "id": "deadly-leisure"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-emperor",
   "metadata": {
    "id": "located-emperor"
   },
   "source": [
    "#### Apply one-hot encode on the categorical data\n",
    "\n",
    "One-hot encoding is applied on the categorical variables, which should not have a different weight or order attached to them, it is presumed that all categorical variables have equivalent \"values\". This means that you cannot simply order them from zero to the number of categories as this would imply that the earlier categories have less \"value\" than later categories.\n",
    "\n",
    "Hint: `sklearn.preprocessing.OneHotEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-stockholm",
   "metadata": {
    "id": "soviet-stockholm"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-teens",
   "metadata": {
    "id": "straight-teens"
   },
   "source": [
    "#### Specify features and targets after applying scaling and one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-private",
   "metadata": {
    "id": "civic-private"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-restoration",
   "metadata": {
    "id": "apparent-restoration"
   },
   "source": [
    "### Implement the linear regression by finding the coefficients using below approaches (3 points)\n",
    "\n",
    "* Find the coefficients using normal equation\n",
    "\n",
    "* Implement batch gradient descent\n",
    "\n",
    "* SGD Regressor from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-shame",
   "metadata": {
    "id": "involved-shame"
   },
   "source": [
    "#### Select the features and target and split the dataset\n",
    "\n",
    "As there are 3 target variables, choose the count (`cnt`) variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-interview",
   "metadata": {
    "id": "excess-interview"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bA2i6mvbf5yZ",
   "metadata": {
    "id": "bA2i6mvbf5yZ"
   },
   "source": [
    "#### Implementation using Normal Equation\n",
    "\n",
    "$\\theta = (X^T X)^{-1} . (X^T Y)$\n",
    "\n",
    "$θ$ is the hypothesis parameter that defines the coefficients\n",
    "\n",
    "$X$ is the input feature value of each instance\n",
    "\n",
    "$Y$ is Output value of each instance\n",
    "\n",
    "To solve the normal equation compute least-squares solution by using `scipy.linalg`\n",
    "\n",
    "Hint: [scipy.linalg.lstsq](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lstsq.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66vjMjeHUTGO",
   "metadata": {
    "id": "66vjMjeHUTGO"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JfHHTPUl6joI",
   "metadata": {
    "id": "JfHHTPUl6joI"
   },
   "source": [
    "#### Implementing Linear regression using batch gradient descent\n",
    "\n",
    "Initialize the random coefficients and optimize the coefficients in the iterative process by calculating cost and finding the gradient.\n",
    "\n",
    "Hint: [gradient descent](https://medium.com/@lope.ai/multivariate-linear-regression-from-scratch-in-python-5c4f219be6a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vQAmuH2FmXWu",
   "metadata": {
    "id": "vQAmuH2FmXWu"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PmZJdg33NlvA",
   "metadata": {
    "id": "PmZJdg33NlvA"
   },
   "source": [
    "#### SGD Regressor\n",
    "\n",
    "Scikit-learn API provides the SGDRegressor class to implement SGD method for regression problems. The SGD regressor applies regularized linear model with SGD learning to build an estimator. A regularizer is a penalty (L1, L2, or Elastic Net) added to the loss function to shrink the model parameters.\n",
    "\n",
    "* Import SGDRegressor from sklearn and fit the data\n",
    "\n",
    "* Predict the test data and find the error\n",
    "\n",
    "Hint: [SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fU1-w4XRNlLA",
   "metadata": {
    "id": "fU1-w4XRNlLA"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-engagement",
   "metadata": {
    "id": "legal-engagement"
   },
   "source": [
    "### Linear regression using sklearn (2 points)\n",
    "\n",
    "Implement the linear regression model using sklearn\n",
    "\n",
    "* Import Linear Regression and fit the train data\n",
    "\n",
    "* Predict the test data and find the error\n",
    "\n",
    "Hint: [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-reserve",
   "metadata": {
    "id": "complicated-reserve"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-morgan",
   "metadata": {
    "id": "quality-morgan"
   },
   "source": [
    "#### Calculate the $R^2$ (coefficient of determination) of the actual and predicted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-jacket",
   "metadata": {
    "id": "important-jacket"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-victim",
   "metadata": {
    "id": "infinite-victim"
   },
   "source": [
    "#### Summarize the importance of features\n",
    "\n",
    "Prediction is the weighted sum of the input values e.g. linear regression. Regularization, such as ridge regression and the elastic net, find a set of coefficients to use in the weighted sum to make a prediction. These coefficients can be used directly as a crude type of feature importance score. \n",
    "This assumes that the input variables have the same scale or have been scaled prior to fitting a model.\n",
    "\n",
    "Use the coefficients obtained through the sklearn Linear Regression implementation and create a bar chart of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-walker",
   "metadata": {
    "id": "affected-walker"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-snowboard",
   "metadata": {
    "id": "convinced-snowboard"
   },
   "source": [
    "### Regularization methods (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-italic",
   "metadata": {
    "id": "twenty-italic"
   },
   "source": [
    "#### Apply Lasso regression\n",
    "\n",
    "* Apply Lasso regression with different alpha values given below and find the best alpha that gives the least error.\n",
    "* Calculate the metrics for the actual and predicted\n",
    "\n",
    "Hint: [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-blake",
   "metadata": {
    "id": "psychological-blake"
   },
   "outputs": [],
   "source": [
    "# setting up alpha\n",
    "alpha = [0.0001, 0.001,0.01, 0.1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-sigma",
   "metadata": {
    "id": "existing-sigma"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-effectiveness",
   "metadata": {
    "id": "figured-effectiveness"
   },
   "source": [
    "#### Apply Ridge regression\n",
    "\n",
    "* Apply Ridge regression with different alpha values given and find the best alpha that gives the least error.\n",
    "* Calculate the metrics for the actual and predicted\n",
    "\n",
    "Hint: [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-initial",
   "metadata": {
    "id": "curious-initial"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-bottom",
   "metadata": {
    "id": "exposed-bottom"
   },
   "source": [
    "#### Apply Elasticnet regression\n",
    "\n",
    "* Apply Elasticnet regression with different alpha values given and find the best alpha that gives the least error.\n",
    "* Calculate the metrics for the actual and predicted\n",
    "\n",
    "Hint: [ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-belief",
   "metadata": {
    "id": "shared-belief"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B6bc_VBGEG7C",
   "metadata": {
    "id": "B6bc_VBGEG7C"
   },
   "source": [
    "### Determine if there is a reduction in error if two target variables are considered\n",
    "\n",
    "Consider (`Casual, Registered`) as target and find the error by implementing Linear Regression model from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i5l5ZviEMy-o",
   "metadata": {
    "id": "i5l5ZviEMy-o"
   },
   "source": [
    "### Report Analysis\n",
    "\n",
    "* Describe your interpretation of the methods that are used to implement linear regression covered in this mini project.\n",
    "* Comment on performance of the algorithms/methods used.\n",
    "* Comment about the nature of the data and fitment of linear regression for this data.\n",
    "* Can you perform a non linear curve fitting using linear regression? If yes, How?\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "M3_NB_MiniProject_1_LinearRegression_Regularization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
